{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Augmentation/Data-prep notebook — Summary & Requirements\n",
        "\n",
        "## What it does\n",
        "1. Convert raw German Traffic Sign Detection Benchmark (GTSDB - FullIJCNN2013) Dataset to YOLO format.  \n",
        "2. Create augmented images by pasting sign crops from German Traffic Sign Recognition Benchmark (GTSRB) Dataset onto empty background frames using polygon placement.  \n",
        "3. Experiments used ~102 empty background frames (these are **NOT** included in the repo), but the notebook contains a cell/script `extract_empty_backgrounds` to recreate empties from your local train images.\n",
        "\n",
        "## Inputs (required to run)\n",
        "- Download GTSRB ([you can download it from here](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)) and use `GTSRB/Train/` and `GTSRB/Train.csv`.  \n",
        "- `data/images/empty_bg_images/` — background images (NOT included). Use the `extract_empty_backgrounds` cell to create these from your training images.  \n",
        "- `data/annotations/allowed_areas.json` — COCO-style polygons (this JSON **is included** in the [repo](https://github.com/WahburRehman/traffic-sign-and-speed-violation-detector)).\n",
        "\n",
        "## Outputs\n",
        "- `data/images_all/`, `data/labels_all/` (YOLO converted)  \n",
        "- `data/images/aug_images_polygon/`, `data/labels/aug_labels_polygon/` (augmented outputs)  \n",
        "- Optional: `data/images/train/`, `data/images/val/`, `data/labels/train/`, `data/labels/val/` after splitting/assembly\n",
        "\n",
        "## How to run (high level)\n",
        "1. Provide required inputs (see above) or run in Colab and mount Drive.  \n",
        "2. Run cells in order: setup → download/extract → convert `gt.txt` → run `extract_empty_backgrounds` (if needed) → augmentation.  \n",
        "3. After augmentation, assemble `train` by combining original and `aug_images_polygon/` or update `data.yaml` accordingly.\n",
        "\n",
        "## Notes: PATH CONFIGURATION - UPDATE THESE FOR YOUR ENVIRONMENT:\n",
        "- PROJ: Your project root directory\n",
        "- GDRIVE_ROOT: Your Google Drive mount point (if using Colab)\n",
        "- Set paths for `GTSRB/Train/` and `GTSRB/Train.csv` accordingly.\n",
        "- Make sure to use the correct path for `allowed_areas.json`."
      ],
      "metadata": {
        "id": "AwtoY0chocUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, zipfile, glob, cv2, json, pathlib, random,  numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "pathlib.PosixPath = pathlib.Path\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "LoivtC56T9bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7p_0xqYPUDl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJ = \"/content/drive/MyDrive/traffic-sign-violation-mvp\"\n",
        "RAW  = f\"{PROJ}/raw\"\n",
        "DATA = f\"{PROJ}/data\"\n",
        "os.makedirs(RAW, exist_ok=True)\n",
        "os.makedirs(DATA, exist_ok=True)\n",
        "print(\"Project root:\", PROJ)\n"
      ],
      "metadata": {
        "id": "bLVyiiA-UEO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zdg0TzeuUFer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download GTSDB (FullIJCNN2013)\n",
        "!mkdir -p {RAW}\n",
        "!wget -q -O {RAW}/FullIJCNN2013.zip https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "\n",
        "# Extract\n",
        "zip_path = f\"{RAW}/FullIJCNN2013.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(f\"{RAW}/FullIJCNN2013\")\n",
        "\n",
        "# Flatten inner folder if needed\n",
        "%cd {RAW}\n",
        "if os.path.exists(\"FullIJCNN2013/FullIJCNN2013\"):\n",
        "    !mv FullIJCNN2013/FullIJCNN2013/* FullIJCNN2013/\n",
        "    !rmdir FullIJCNN2013/FullIJCNN2013\n",
        "\n",
        "!ls FullIJCNN2013 | head\n"
      ],
      "metadata": {
        "id": "op4CxoDdUFQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGCREvZrUM6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_DIR = f\"{RAW}/FullIJCNN2013\"\n",
        "GT_FILE = f\"{IMG_DIR}/gt.txt\"\n",
        "\n",
        "OUT_ALL_IMG = f\"{DATA}/images_all\"\n",
        "OUT_ALL_LAB = f\"{DATA}/labels_all\"\n",
        "os.makedirs(OUT_ALL_IMG, exist_ok=True)\n",
        "os.makedirs(OUT_ALL_LAB, exist_ok=True)\n",
        "\n",
        "ann = {}  # stem -> list of yolo lines\n",
        "with open(GT_FILE, \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\";\")\n",
        "        if len(parts) != 6:\n",
        "            continue\n",
        "        fname, x1, y1, x2, y2, cls = parts\n",
        "        x1, y1, x2, y2, cls = map(int, [x1, y1, x2, y2, cls])\n",
        "\n",
        "        img_path = os.path.join(IMG_DIR, fname)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        H, W = img.shape[:2]\n",
        "        x_c = (x1 + x2) / 2.0 / W\n",
        "        y_c = (y1 + y2) / 2.0 / H\n",
        "        bw  = (x2 - x1) / W\n",
        "        bh  = (y2 - y1) / H\n",
        "\n",
        "        stem = Path(fname).stem\n",
        "        ann.setdefault(stem, []).append(f\"{cls} {x_c:.6f} {y_c:.6f} {bw:.6f} {bh:.6f}\")\n",
        "\n",
        "ppm_files = sorted(glob.glob(os.path.join(IMG_DIR, \"*.ppm\")))\n",
        "n_img, n_lab = 0, 0\n",
        "for ppm in ppm_files:\n",
        "    img = cv2.imread(ppm)\n",
        "    if img is None:\n",
        "        continue\n",
        "    stem = Path(ppm).stem\n",
        "    out_img = os.path.join(OUT_ALL_IMG, f\"{stem}.jpg\")\n",
        "    if not os.path.exists(out_img):\n",
        "        cv2.imwrite(out_img, img); n_img += 1\n",
        "\n",
        "    lines = ann.get(stem, [])\n",
        "    with open(os.path.join(OUT_ALL_LAB, f\"{stem}.txt\"), \"w\") as lf:\n",
        "            lf.write(\"\\n\".join(lines))\n",
        "    n_lab += 1\n",
        "\n",
        "print(f\"Images written: {n_img} | Label files: {n_lab} (some labels may be empty if no sign)\")\n"
      ],
      "metadata": {
        "id": "apLVgt2LUMeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "16M6weRcUNXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_IMG = f\"{PROJ}/data/images_all\"\n",
        "ALL_LAB = f\"{PROJ}/data/labels_all\"\n",
        "\n",
        "TRAIN_IMG = f\"{PROJ}/data/images/train\"\n",
        "VAL_IMG   = f\"{PROJ}/data/images/val\"\n",
        "TRAIN_LAB = f\"{PROJ}/data/labels/train\"\n",
        "VAL_LAB   = f\"{PROJ}/data/labels/val\"\n",
        "for d in [TRAIN_IMG, VAL_IMG, TRAIN_LAB, VAL_LAB]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# All stems\n",
        "stems = [Path(p).stem for p in glob.glob(f\"{ALL_IMG}/*.jpg\")]\n",
        "random.Random(42).shuffle(stems)\n",
        "\n",
        "# Pick 600 train + 300 val\n",
        "train_stems = stems[:600]\n",
        "val_stems   = stems[600:900]\n",
        "\n",
        "def cp(stem, src_img, src_lab, dst_img, dst_lab):\n",
        "    si, sl = f\"{src_img}/{stem}.jpg\", f\"{src_lab}/{stem}.txt\"\n",
        "    if os.path.exists(si): shutil.copy2(si, dst_img)\n",
        "    if os.path.exists(sl): shutil.copy2(sl, dst_lab)\n",
        "\n",
        "for s in train_stems:\n",
        "    cp(s, ALL_IMG, ALL_LAB, TRAIN_IMG, TRAIN_LAB)\n",
        "for s in val_stems:\n",
        "    cp(s, ALL_IMG, ALL_LAB, VAL_IMG, VAL_LAB)\n",
        "\n",
        "print(\"Train imgs:\", len(glob.glob(TRAIN_IMG+\"/*.jpg\")))\n",
        "print(\"Val   imgs:\", len(glob.glob(VAL_IMG+\"/*.jpg\")))\n"
      ],
      "metadata": {
        "id": "prdg0gJFWJLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c1XilHbNWJCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract_empty_backgrounds\n",
        "\n",
        "TRAIN_IMG_DIR = f\"{PROJ}/data/images/train\"\n",
        "TRAIN_LAB_DIR = f\"{PROJ}/data/labels/train\"\n",
        "OUT_DIR = f\"{PROJ}/data/images/empty_bg_images\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "jpg_paths = sorted(glob.glob(os.path.join(TRAIN_IMG_DIR, \"*.jpg\")))\n",
        "empty_count = 0\n",
        "copied = 0\n",
        "\n",
        "for p in jpg_paths:\n",
        "    stem = Path(p).stem\n",
        "    lab = os.path.join(TRAIN_LAB_DIR, f\"{stem}.txt\")\n",
        "\n",
        "    # consider empty if label missing OR file exists but size == 0\n",
        "    is_empty = (not os.path.exists(lab)) or (os.path.exists(lab) and os.path.getsize(lab) == 0)\n",
        "\n",
        "    if is_empty:\n",
        "        dst = os.path.join(OUT_DIR, Path(p).name)\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.copy2(p, dst)   # use shutil.move(p, dst) if you want to move instead\n",
        "            copied += 1\n",
        "        empty_count += 1\n",
        "\n",
        "print(f\"Total train images checked: {len(jpg_paths)}\")\n",
        "print(f\"Images with empty/missing labels: {empty_count}\")\n",
        "print(f\"Images copied to '{OUT_DIR}': {copied}\")\n"
      ],
      "metadata": {
        "id": "24nDdH37cjrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-aT3KhXZcjeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxiqmEkwQaPT"
      },
      "outputs": [],
      "source": [
        "GDRIVE_ROOT = \"/content/drive/MyDrive\"\n",
        "\n",
        "# COCO-style JSON with per-image allowed polygons/bboxes\n",
        "ALLOWED_JSON = f\"{GDRIVE_ROOT}/traffic-sign-violation-mvp/allowed_areas.json\"\n",
        "BG_BASE_DIR = f\"{GDRIVE_ROOT}/traffic-sign-violation-mvp/data/images/empty_bg_images\"\n",
        "GTSRB_TRAIN_DIR = f\"{GDRIVE_ROOT}/GTSRB/Train\"\n",
        "GTSRB_TRAIN_CSV = f\"{GDRIVE_ROOT}/GTSRB/Train.csv\"\n",
        "\n",
        "# Output directories\n",
        "OUT_IMG_DIR = f\"{GDRIVE_ROOT}/traffic-sign-violation-mvp/data/images/aug_images_polygon\"\n",
        "OUT_LBL_DIR = f\"{GDRIVE_ROOT}/traffic-sign-violation-mvp/data/labels/aug_labels_polygon\"\n",
        "Path(OUT_IMG_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(OUT_LBL_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Augmentation parameters\n",
        "TARGET_PER_CLASS = 306\n",
        "MAX_SIGN_REUSE = 5\n",
        "\n",
        "CLASSES_TO_GENERATE = [0]  # Classe 0\n",
        "# CLASSES_TO_GENERATE = list(range(1, 11))  # Classes 1-10\n",
        "# CLASSES_TO_GENERATE = list(range(11, 21))  # Classes 11-20\n",
        "# CLASSES_TO_GENERATE = list(range(21, 31))  # Classes 21-30\n",
        "# CLASSES_TO_GENERATE = list(range(31, 43))  # Classes 31-42\n",
        "\n",
        "ALL_CLASSES = list(range(43))\n",
        "random.seed(42)\n",
        "\n",
        "# --- Load metadata (NOT images) ---\n",
        "print(\"Loading metadata...\")\n",
        "\n",
        "# Load allowed areas JSON\n",
        "with open(ALLOWED_JSON, 'r') as f:\n",
        "    allowed_data = json.load(f)\n",
        "\n",
        "# Create mapping from image_id to allowed areas\n",
        "image_areas = {}\n",
        "for ann in allowed_data['annotations']:\n",
        "    image_id = ann['image_id']\n",
        "    if image_id not in image_areas:\n",
        "        image_areas[image_id] = []\n",
        "    image_areas[image_id].append(ann)\n",
        "\n",
        "# Create mapping from filename to image data\n",
        "image_info = {img['file_name']: img for img in allowed_data['images']}\n",
        "\n",
        "# Load GTSRB CSV for ROI information\n",
        "df = pd.read_csv(GTSRB_TRAIN_CSV)\n",
        "roi_map = {}\n",
        "for _, row in df.iterrows():\n",
        "    roi_map[row['Path']] = (row['Roi.X1'], row['Roi.Y1'], row['Roi.X2'], row['Roi.Y2'])\n",
        "\n",
        "# Get all background images and sort them\n",
        "bg_images = sorted([f for f in os.listdir(BG_BASE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "print(f\"Found {len(bg_images)} background images\")\n",
        "\n",
        "# Get all sign image PATHS\n",
        "sign_paths_by_class = {}\n",
        "for cls in ALL_CLASSES:\n",
        "    cls_dir = Path(GTSRB_TRAIN_DIR) / str(cls)\n",
        "    sign_paths = []\n",
        "    for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.ppm']:\n",
        "        sign_paths.extend([str(p) for p in cls_dir.glob(ext)])\n",
        "    sign_paths_by_class[cls] = sign_paths\n",
        "    print(f\"Class {cls}: {len(sign_paths)} signs\")\n",
        "\n",
        "# --- Helper functions ---\n",
        "def get_sign_roi(sign_path):\n",
        "    \"\"\"Extract ROI from sign image using CSV data\"\"\"\n",
        "    # Get relative path from GTSRB root\n",
        "    rel_path = str(Path(sign_path).relative_to(Path(GTSRB_TRAIN_DIR).parent))\n",
        "\n",
        "    if rel_path in roi_map:\n",
        "        return roi_map[rel_path]\n",
        "\n",
        "    # Try with forward slashes for consistency\n",
        "    rel_path_forward = rel_path.replace('\\\\', '/')\n",
        "    if rel_path_forward in roi_map:\n",
        "        return roi_map[rel_path_forward]\n",
        "\n",
        "    return None\n",
        "\n",
        "def load_and_process_sign(sign_path):\n",
        "    \"\"\"Load and process a sign image ON DEMAND\"\"\"\n",
        "    img = cv2.imread(sign_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    # Crop to ROI coordinates\n",
        "    roi = get_sign_roi(sign_path)\n",
        "    if roi:\n",
        "        x1, y1, x2, y2 = roi\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(img.shape[1], x2), min(img.shape[0], y2)\n",
        "        if x2 > x1 and y2 > y1:\n",
        "            img = img[y1:y2, x1:x2]\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_polygon_center(polygon):\n",
        "    \"\"\"Calculate center point of a polygon\"\"\"\n",
        "    points = np.array(polygon).reshape(-1, 2)\n",
        "    center = np.mean(points, axis=0)\n",
        "    return int(center[0]), int(center[1])\n",
        "\n",
        "def resize_to_fit_bbox(sign_img, bbox, max_scale=0.8):\n",
        "    \"\"\"Resize sign to fit within bbox - NO cosmetic alterations\"\"\"\n",
        "    bbox_w = bbox[2]\n",
        "    bbox_h = bbox[3]\n",
        "\n",
        "    sign_h, sign_w = sign_img.shape[:2]\n",
        "\n",
        "    # Calculate scale factors\n",
        "    scale_w = (bbox_w * max_scale) / sign_w\n",
        "    scale_h = (bbox_h * max_scale) / sign_h\n",
        "    scale = min(scale_w, scale_h)\n",
        "\n",
        "    # Small random variation for natural look\n",
        "    scale *= random.uniform(0.8, 0.95)\n",
        "\n",
        "    new_w = max(10, int(sign_w * scale))\n",
        "    new_h = max(10, int(sign_h * scale))\n",
        "\n",
        "    return cv2.resize(sign_img, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "def create_soft_mask(sign_img):\n",
        "    \"\"\"Create soft mask for blending\"\"\"\n",
        "    if len(sign_img.shape) == 3:\n",
        "        gray = cv2.cvtColor(sign_img, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = sign_img\n",
        "\n",
        "    # Simple thresholding to remove white backgrounds\n",
        "    _, mask = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Soft edges for natural blending\n",
        "    mask = cv2.GaussianBlur(mask, (3, 3), 0.5)\n",
        "    return mask\n",
        "\n",
        "def alpha_blend(bg, sign, mask, center_x, center_y):\n",
        "    \"\"\"Blend sign onto background\"\"\"\n",
        "    h, w = sign.shape[:2]\n",
        "    x1 = max(0, center_x - w // 2)\n",
        "    y1 = max(0, center_y - h // 2)\n",
        "    x2 = min(bg.shape[1], x1 + w)\n",
        "    y2 = min(bg.shape[0], y1 + h)\n",
        "\n",
        "    # Adjust sign and mask to fit\n",
        "    sign = sign[0:y2-y1, 0:x2-x1]\n",
        "    mask = mask[0:y2-y1, 0:x2-x1]\n",
        "\n",
        "    if sign.size == 0:\n",
        "        return bg, (0, 0, 0, 0)\n",
        "\n",
        "    # Convert mask to 3 channels\n",
        "    if len(mask.shape) == 2:\n",
        "        mask_3ch = cv2.merge([mask, mask, mask])\n",
        "    else:\n",
        "        mask_3ch = mask\n",
        "\n",
        "    mask_float = mask_3ch.astype(float) / 255.0\n",
        "\n",
        "    # Blend\n",
        "    bg_roi = bg[y1:y2, x1:x2]\n",
        "    blended = bg_roi.astype(float) * (1 - mask_float) + sign.astype(float) * mask_float\n",
        "    blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
        "\n",
        "    bg[y1:y2, x1:x2] = blended\n",
        "\n",
        "    # YOLO bbox\n",
        "    bbox_x = (x1 + x2) / 2 / bg.shape[1]\n",
        "    bbox_y = (y1 + y2) / 2 / bg.shape[0]\n",
        "    bbox_w = (x2 - x1) / bg.shape[1]\n",
        "    bbox_h = (y2 - y1) / bg.shape[0]\n",
        "\n",
        "    return bg, (bbox_x, bbox_y, bbox_w, bbox_h)\n",
        "\n",
        "# --- Main generation logic ---\n",
        "def generate_augmented_images():\n",
        "    # Track sign usage by PATH only (memory efficient)\n",
        "    sign_usage = {cls: {sign_path: 0 for sign_path in sign_paths_by_class[cls]}\n",
        "                 for cls in ALL_CLASSES}\n",
        "\n",
        "    for target_class in CLASSES_TO_GENERATE:\n",
        "        print(f\"\\nGenerating images for class {target_class}...\")\n",
        "        generated_count = 0\n",
        "        bg_index = 0\n",
        "\n",
        "        while generated_count < TARGET_PER_CLASS:\n",
        "            # Cycle through background images\n",
        "            bg_filename = bg_images[bg_index % len(bg_images)]\n",
        "            bg_index += 1\n",
        "\n",
        "            bg_path = os.path.join(BG_BASE_DIR, bg_filename)\n",
        "\n",
        "            if bg_filename not in image_info:\n",
        "                continue\n",
        "\n",
        "            img_info = image_info[bg_filename]\n",
        "            image_id = img_info['id']\n",
        "\n",
        "            if image_id not in image_areas or not image_areas[image_id]:\n",
        "                continue\n",
        "\n",
        "            # Load background image\n",
        "            bg_img = cv2.imread(bg_path)\n",
        "            if bg_img is None:\n",
        "                continue\n",
        "\n",
        "            areas = image_areas[image_id]\n",
        "\n",
        "            # Select main sign path\n",
        "            available_signs = [s for s in sign_paths_by_class[target_class]\n",
        "                             if sign_usage[target_class][s] < MAX_SIGN_REUSE]\n",
        "\n",
        "            if not available_signs:\n",
        "                print(f\"No available signs for class {target_class}\")\n",
        "                break\n",
        "\n",
        "            main_sign_path = random.choice(available_signs)\n",
        "\n",
        "            # LOAD SIGN ON DEMAND (memory efficient)\n",
        "            main_sign_img = load_and_process_sign(main_sign_path)\n",
        "            if main_sign_img is None or main_sign_img.size == 0:\n",
        "                continue\n",
        "\n",
        "            # Choose area and place sign\n",
        "            main_area = random.choice(areas)\n",
        "            center_x, center_y = get_polygon_center(main_area['segmentation'][0])\n",
        "\n",
        "            main_sign_resized = resize_to_fit_bbox(main_sign_img, main_area['bbox'])\n",
        "            mask = create_soft_mask(main_sign_resized)\n",
        "\n",
        "            bg_with_sign, main_bbox = alpha_blend(bg_img.copy(), main_sign_resized, mask, center_x, center_y)\n",
        "\n",
        "            # YOLO annotations\n",
        "            yolo_annotations = [f\"{target_class} {main_bbox[0]:.6f} {main_bbox[1]:.6f} {main_bbox[2]:.6f} {main_bbox[3]:.6f}\"]\n",
        "\n",
        "            # Add secondary signs if multiple areas\n",
        "            other_areas = [area for area in areas if area != main_area]\n",
        "            for area in other_areas:\n",
        "                other_class = random.choice([c for c in ALL_CLASSES if c != target_class])\n",
        "                other_sign_path = random.choice(sign_paths_by_class[other_class])\n",
        "\n",
        "                # LOAD ON DEMAND\n",
        "                other_sign_img = load_and_process_sign(other_sign_path)\n",
        "                if other_sign_img is None or other_sign_img.size == 0:\n",
        "                    continue\n",
        "\n",
        "                center_x, center_y = get_polygon_center(area['segmentation'][0])\n",
        "                other_sign_resized = resize_to_fit_bbox(other_sign_img, area['bbox'])\n",
        "                other_mask = create_soft_mask(other_sign_resized)\n",
        "\n",
        "                bg_with_sign, other_bbox = alpha_blend(bg_with_sign, other_sign_resized, other_mask, center_x, center_y)\n",
        "                yolo_annotations.append(f\"{other_class} {other_bbox[0]:.6f} {other_bbox[1]:.6f} {other_bbox[2]:.6f} {other_bbox[3]:.6f}\")\n",
        "\n",
        "            # Save results\n",
        "            output_filename = f\"cls{target_class}_bg{Path(bg_filename).stem}_sign{Path(main_sign_path).stem}_{generated_count:04d}\"\n",
        "            cv2.imwrite(os.path.join(OUT_IMG_DIR, f\"{output_filename}.jpg\"), bg_with_sign)\n",
        "\n",
        "            with open(os.path.join(OUT_LBL_DIR, f\"{output_filename}.txt\"), 'w') as f:\n",
        "                f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "            # Update usage and free memory\n",
        "            sign_usage[target_class][main_sign_path] += 1\n",
        "            generated_count += 1\n",
        "\n",
        "            if generated_count % 50 == 0:\n",
        "                print(f\"Generated {generated_count}/{TARGET_PER_CLASS}\")\n",
        "                # Explicit memory cleanup\n",
        "                import gc\n",
        "                gc.collect()\n",
        "\n",
        "        print(f\"Completed class {target_class}: {generated_count} images\")\n",
        "\n",
        "# Run generation\n",
        "generate_augmented_images()\n",
        "print(\"\\nAugmentation complete!\")"
      ]
    }
  ]
}